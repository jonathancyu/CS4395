{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79507e47",
   "metadata": {},
   "source": [
    "# 1 Read in data\n",
    "This cell reads in the data and displays the count of each author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0f9833ca",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HAMILTON                49\n",
       "MADISON                 15\n",
       "HAMILTON OR MADISON     11\n",
       "JAY                      5\n",
       "HAMILTON AND MADISON     3\n",
       "Name: author, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"federalist.csv\")\n",
    "df['author'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d6d79e",
   "metadata": {},
   "source": [
    "# 2, 3 Preprocessing\n",
    "This cell removes stopwords, splits the data into train and test splits, then performes tf-idf vectorization on the training data, and applied to train and test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "88946e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: X: (66,), y: (66,)\n",
      "Test shape: X: (17,), y: (17,)\n",
      "Train shape: X: (66, 7876), y: (66,)\n",
      "Test shape: X: (17, 7876), y: (17,)\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "stopwords = set(stopwords.words(\"english\"))\n",
    "vectorizer = TfidfVectorizer(stop_words=stopwords)\n",
    "\n",
    "X = df.text\n",
    "y = df.author\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, train_size=0.8, random_state=1234)\n",
    "\n",
    "print(f\"Train shape: X: {X_train.shape}, y: {y_train.shape}\")\n",
    "print(f\"Test shape: X: {X_test.shape}, y: {y_test.shape}\")\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=stopwords)\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "print(f\"Train shape: X: {X_train.shape}, y: {y_train.shape}\")\n",
    "print(f\"Test shape: X: {X_test.shape}, y: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dca87a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (66, 7752)\n",
      "Test shape: (2, 7752)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train shape: {v_train.shape}\")\n",
    "print(f\"Test shape: {v_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c947e9a",
   "metadata": {},
   "source": [
    "# 4 Naive Bayes Model\n",
    "This configuration of Naive Bayes is clearly suboptimal, as there is not even 59% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fc511fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.5882352941176471\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "bernoulli_nb = BernoulliNB()\n",
    "bernoulli_nb.fit(X_train, y_train)\n",
    "prediction = bernoulli_nb.predict(X_test)\n",
    "\n",
    "print(f\"Accuracy on test set: {accuracy_score(y_test, prediction)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b82716",
   "metadata": {},
   "source": [
    "# 5 Naive Bayes Take 2\n",
    "This cell retries Naive Bayes with a CountVectorizer using bigrams as well as max features of 1000. This configuration is a great improvement on the previous one, as it has 94% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "775b8385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.9411764705882353\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, train_size=0.8, random_state=1234)\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words=stopwords, \n",
    "                             ngram_range=(1,2), \n",
    "                             max_features=1000)\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "bernoulli_nb = BernoulliNB()\n",
    "bernoulli_nb.fit(X_train, y_train)\n",
    "prediction = bernoulli_nb.predict(X_test)\n",
    "\n",
    "print(f\"Accuracy on test set: {accuracy_score(y_test, prediction)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b6c8a1",
   "metadata": {},
   "source": [
    "# 6 Logistic Regression\n",
    "In this cell, I try to predict authors using logistic regression.\n",
    "This leads to poor accuracy, which is curiously the exact same as the first NB accuracy. I was able to improve the accuracy to 88% by adding the parameter C=1000, which decreases regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f6086c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Try 1 accuracy score: 0.5882352941176471\n",
      "Try 2 accuracy score: 0.8823529411764706\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, train_size=0.8, random_state=1234)\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)\n",
    "print(f\"Try 1 accuracy score: {accuracy_score(y_test, classifier.predict(X_test))}\")\n",
    "\n",
    "classifier = LogisticRegression(C=1000)\n",
    "classifier.fit(X_train, y_train)\n",
    "print(f\"Try 2 accuracy score: {accuracy_score(y_test, classifier.predict(X_test))}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525a6d4a",
   "metadata": {},
   "source": [
    "# 7 Neural Network\n",
    "I tried 50\\*50 different combinations, as well as different activation functions, and found that 23 hidden layers with 5 nodes each, all using sigmoid as the activation function, gave the highest accuracy of 0.9411764705882353."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d12785",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best: (1, 1), acc=0.5882352941176471\n",
      "New best: (1, 2), acc=0.7058823529411765\n",
      "New best: (1, 13), acc=0.7647058823529411\n",
      "New best: (6, 43), acc=0.8235294117647058\n",
      "New best: (24, 20), acc=0.8823529411764706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python39\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:559: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "c:\\python39\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:559: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, train_size=0.8, random_state=1234)\n",
    "\n",
    "maxconfig = (0,0)\n",
    "bestaccuracy = 0\n",
    "for i in range(1,50):\n",
    "    for j in range(1,50):\n",
    "        config = (i,j)\n",
    "        vectorizer = TfidfVectorizer(stop_words=stopwords, binary=True)\n",
    "        NN = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                           hidden_layer_sizes=config, random_state=1,\n",
    "                           max_iter=10000, activation='relu'        \n",
    "                        )\n",
    "        pipe = Pipeline([\n",
    "            ('tfidf', vectorizer),\n",
    "            ('neuralnet', NN),\n",
    "        ])\n",
    "\n",
    "        pipe.fit(X_train, y_train)\n",
    "        acc = np.mean(pipe.predict(X_test)==y_test)\n",
    "        #print(f\"{config}: acc={acc}\")\n",
    "        if acc > bestaccuracy:\n",
    "            maxconfig = (i,j)\n",
    "            bestaccuracy=acc\n",
    "        \n",
    "            print(f\"New best: {maxconfig}, acc={acc}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "e94c19e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9411764705882353\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import numpy as np\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, train_size=0.8, random_state=1234)\n",
    "vectorizer = TfidfVectorizer(stop_words=stopwords, binary=True)\n",
    "NN = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                   hidden_layer_sizes=(5, 23), random_state=1,\n",
    "                   max_iter=10000, activation='logistic'        \n",
    "                )\n",
    "pipe = Pipeline([\n",
    "    ('tfidf', vectorizer),\n",
    "    ('neuralnet', NN),\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "print(f\"Accuracy: {np.mean(pipe.predict(X_test)==y_test)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
