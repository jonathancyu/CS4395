{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ffb7b7b",
   "metadata": {},
   "source": [
    "# 1\n",
    "Wordnet is a hierarchical database of words, organized and connected by semantic meaning. It contains definitions, synonyms, and examples for each word. Wordnet is incredibly useful for all facets of natural language processing, as it provides semantic meaning to every word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f1178e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bcfc41",
   "metadata": {},
   "source": [
    "# 2\n",
    "The following cell gets the synsets of the word \"good\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7efc5bb1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset: [Synset('good.n.01'), Synset('good.n.02'), Synset('good.n.03'), Synset('commodity.n.01'), Synset('good.a.01'), Synset('full.s.06'), Synset('good.a.03'), Synset('estimable.s.02'), Synset('beneficial.s.01'), Synset('good.s.06'), Synset('good.s.07'), Synset('adept.s.01'), Synset('good.s.09'), Synset('dear.s.02'), Synset('dependable.s.04'), Synset('good.s.12'), Synset('good.s.13'), Synset('effective.s.04'), Synset('good.s.15'), Synset('good.s.16'), Synset('good.s.17'), Synset('good.s.18'), Synset('good.s.19'), Synset('good.s.20'), Synset('good.s.21'), Synset('well.r.01'), Synset('thoroughly.r.02')]\n"
     ]
    }
   ],
   "source": [
    "synsets = wn.synsets(\"good\")\n",
    "synset = synsets[1]\n",
    "\n",
    "print(f\"Synset: {synsets}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7248b8f7",
   "metadata": {},
   "source": [
    "# 3\n",
    "It seems like the wordnet hierarchy is ordered from top to bottom. At the bottom, there are specific words. As you go further up, the hypernyms encapsulate everything until you reach the highest level, entity. There are many more nouns at the bottom of the hierarchy than the top. At the highest level of all nouns is the \"entity\" synset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4ce1bea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Definition: moral excellence or admirableness\n",
      "Examples: ['there is much good to be found in people']\n",
      "Lemmas: [Lemma('good.n.02.good'), Lemma('good.n.02.goodness')]\n",
      "[Synset('good.n.02')]\n",
      "[Synset('morality.n.01')]\n",
      "[Synset('quality.n.01')]\n",
      "[Synset('attribute.n.02')]\n",
      "[Synset('abstraction.n.06')]\n",
      "[Synset('entity.n.01')]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Definition: {synset.definition()}\")\n",
    "print(f\"Examples: {synset.examples()}\")\n",
    "print(f\"Lemmas: {synset.lemmas()}\")\n",
    "\n",
    "current = [synset]\n",
    "while len(current) > 0:\n",
    "        print(current)\n",
    "        current = current[0].hypernyms()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e588178",
   "metadata": {},
   "source": [
    "# 4 \n",
    "The following cell prints the synset's hypernyms, hyponyms, meronyms, holonyms, and antonyms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "94240bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hypernyms: [Synset('morality.n.01')]\n",
      "Hyponyms: [Synset('beneficence.n.02'), Synset('benignity.n.01'), Synset('kindness.n.01'), Synset('saintliness.n.01'), Synset('summum_bonum.n.01'), Synset('virtue.n.01'), Synset('virtue.n.04')]\n",
      "Meronyms: []\n",
      "Holonyms: []\n",
      "Antonyms: [Lemma('evil.n.03.evil'), Lemma('evil.n.03.evilness')]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Hypernyms: {synset.hypernyms()}\")\n",
    "print(f\"Hyponyms: {synset.hyponyms()}\")\n",
    "print(f\"Meronyms: {synset.part_meronyms()}\")\n",
    "print(f\"Holonyms: {synset.part_holonyms()}\")\n",
    "antonyms = []\n",
    "for l in synset.lemmas():\n",
    "    for a in l.antonyms():\n",
    "        antonyms.append(a)\n",
    "print(f\"Antonyms: {antonyms}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a87f0b",
   "metadata": {},
   "source": [
    "# 5\n",
    "The following cell outputs all synsets of the given verb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d56dd3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "verb = wn.synsets(\"jog\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549245cd",
   "metadata": {},
   "source": [
    "# 6\n",
    "The following cell will find the hierarchy of the given verb.\n",
    "The hierarchy of verbs in wordnet is similar to the hierarchy of nouns. As you go up the hierarchy from the bottom, the verbs get more general. Unlike the noun hierarchy, the verb hierarchy doesn't originate from the same synset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "020a66c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('jog.v.03')]\n",
      "[Synset('run.v.01')]\n",
      "[Synset('travel_rapidly.v.01')]\n",
      "[Synset('travel.v.01')]\n"
     ]
    }
   ],
   "source": [
    "current = [verb[5]]\n",
    "while len(current) > 0:\n",
    "        print(current)\n",
    "        current = current[0].hypernyms()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04db6d51",
   "metadata": {},
   "source": [
    "# 7\n",
    "The following cell uses morphy to find different forms of the word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "35325c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jog\n",
      "jog\n",
      "jog\n"
     ]
    }
   ],
   "source": [
    "print(wn.morphy('jog', wn.NOUN))\n",
    "print(wn.morphy('jogs', wn.NOUN))\n",
    "print(wn.morphy('jogged', wn.VERB))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c418261c",
   "metadata": {},
   "source": [
    "# 8\n",
    "The following cell computes the similarity between two words. The Wu-Palmer algorithm shows that lion and tiger are somewhat similar, however they aren't the exact same word. This makes sense, given they are in the same family of words (felines), however they refer to two distinct entities. \n",
    "For the Lesk algorithm, it seems longer sentences result in more context which in turn leads to better results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "aa9bc938",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5217391304347826\n",
      "Synset('jog.v.06')\n",
      "Synset('trot.v.01')\n",
      "Synset('square_up.v.02')\n"
     ]
    }
   ],
   "source": [
    "from nltk.wsd import lesk\n",
    "\n",
    "lion = wn.synsets(\"lion\")[0]\n",
    "tiger = wn.synsets(\"tiger\")[0]\n",
    "print(wn.wup_similarity(lion, tiger))\n",
    "\n",
    "print(lesk(\"He jogged to work\".split(), \"jog\"))\n",
    "print(lesk(\"The experience jogged his memory\".split(), \"jog\"))\n",
    "print(lesk(\"He forgot about this, but the experience jogged his memory\".split(), \"jog\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4690e7",
   "metadata": {},
   "source": [
    "# 9\n",
    "SentiWordNet is a sentiment analysis dataset for identifying intention and opinion in natural language. It uses three different sentiment scores in order to try to quantify sentiment. SentiWordNet can be used for identifying bias in news articles, or for monitoring polarization on social media.\n",
    "\n",
    "The biggest thing I observed is that each score is completely independent of the context around it. Having these scores can be incredibly useful for NLP applications, however they can be misleading in edge cases such as double negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "133f5abd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive score =  0.125\n",
      "Negative score =  0.0\n",
      "Objective score =  0.875\n",
      "Pos: 0.0, Neg: 0.0\n",
      "Pos: 0.0, Neg: 0.0\n",
      "Pos: 0.0, Neg: 0.0\n",
      "Pos: 0.75, Neg: 0.0\n",
      "Pos: 0.0, Neg: 0.0\n",
      "Pos: 0.0, Neg: 0.0\n",
      "Pos: 0.0, Neg: 0.375\n",
      "Pos: 0.0, Neg: 0.0\n",
      "Pos: 0.125, Neg: 0.0\n",
      "Pos: 0.0, Neg: 0.0\n",
      "Total Pos: 0.375, Total Neg: 0.875\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import sentiwordnet as swn\n",
    "word = \"outrage.n.02\"\n",
    "breakdown = swn.senti_synset(word)\n",
    "print(\"Positive score = \", breakdown.pos_score())\n",
    "print(\"Negative score = \", breakdown.neg_score())\n",
    "print(\"Objective score = \", breakdown.obj_score())\n",
    "\n",
    "sentence = \"I was walking my beautiful dog in the ugly park down the street\"\n",
    "neg = 0\n",
    "pos = 0\n",
    "for word in sentence.split():\n",
    "    syn_list = list(swn.senti_synsets(word))\n",
    "    if syn_list:\n",
    "        syn = syn_list[0]\n",
    "        neg += syn.pos_score()\n",
    "        pos += syn.neg_score()\n",
    "        print(f\"Pos: {syn.pos_score()}, Neg: {syn.neg_score()}\")\n",
    "print(f\"Total Pos: {pos}, Total Neg: {neg}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fdbba58",
   "metadata": {},
   "source": [
    "# 10\n",
    "Collocation is when two or more words are combined more than statistically is normal, and when you can't substitute any of the words to get the same meaning. This can be useful to determine idioms and phrases that act as an atomic unit.\n",
    "In the following cell, I compute the mutual information between the words \"criminal\" and \"justice\". The mutual information formula gave a relatively high score, but not the highest I've seen, which makes sense as criminal justice is a legitimate collocation. I would interpret this score as criminal justice is a collocation, however they are often used without eachother which results in a lower mutual information score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "49a25110",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('CRIMINAL', 'JUSTICE')\n",
      "6.392317422778761\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import math\n",
    "from nltk.collocations import BigramCollocationFinder\n",
    "from nltk.metrics import BigramAssocMeasures\n",
    "from nltk.book import text4\n",
    "\n",
    "def bigram_word_feats(words, score_fn=BigramAssocMeasures.chi_sq, n=200):\n",
    "    bigram_finder = BigramCollocationFinder.from_words(words)\n",
    "    bigrams = bigram_finder.nbest(score_fn, n)\n",
    "    return [ngram for ngram in itertools.chain(words, bigrams)\n",
    "                if type(ngram) == tuple]\n",
    "bigram = bigram_word_feats(text4)[11]\n",
    "print(bigram)\n",
    "text = ' '.join(text4.tokens)\n",
    "\n",
    "vocab = len(set(text))\n",
    "p01 = text.count(bigram[0] + \" \" + bigram[1])/vocab\n",
    "p0 = text.count(bigram[0])/vocab\n",
    "p1 = text.count(bigram[1])/vocab\n",
    "pmi = math.log2(p01/(p0*p1))\n",
    "print(pmi)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
