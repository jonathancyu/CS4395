{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4517cd7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('jack', 'jumped'),\n",
       " ('jumped', 'over'),\n",
       " ('over', 'the'),\n",
       " ('the', 'clk'),\n",
       " ('clk', 'erjk')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ngrams(word_tokenize(\"jack jumped over the clk erjk\"), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "91911251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Italian\n",
      "2 English\n",
      "3 Italian\n",
      "4 French\n",
      "5 French\n",
      "6 English\n",
      "7 English\n",
      "8 English\n",
      "9 French\n",
      "10 French\n",
      "11 English\n",
      "12 Italian\n",
      "13 English\n",
      "14 English\n",
      "15 French\n",
      "16 English\n",
      "17 French\n",
      "18 French\n",
      "19 Italian\n",
      "20 English\n",
      "21 Italian\n",
      "22 French\n",
      "23 Italian\n",
      "24 English\n",
      "25 Italian\n",
      "26 English\n",
      "27 English\n",
      "28 English\n",
      "29 English\n",
      "30 English\n",
      "31 English\n",
      "32 English\n",
      "33 English\n",
      "34 French\n",
      "35 French\n",
      "36 Italian\n",
      "37 French\n",
      "38 English\n",
      "39 French\n",
      "40 Italian\n",
      "41 Italian\n",
      "42 French\n",
      "43 Italian\n",
      "44 English\n",
      "45 French\n",
      "46 Italian\n",
      "47 French\n",
      "48 Italian\n",
      "49 French\n",
      "50 Italian\n",
      "51 English\n",
      "52 Italian\n",
      "53 Italian\n",
      "54 Italian\n",
      "55 Italian\n",
      "56 Italian\n",
      "57 Italian\n",
      "58 English\n",
      "59 French\n",
      "60 French\n",
      "61 Italian\n",
      "62 French\n",
      "63 English\n",
      "64 Italian\n",
      "65 Italian\n",
      "66 French\n",
      "67 French\n",
      "68 English\n",
      "69 Italian\n",
      "70 Italian\n",
      "71 English\n",
      "72 Italian\n",
      "73 English\n",
      "74 English\n",
      "75 English\n",
      "76 English\n",
      "77 English\n",
      "78 Italian\n",
      "79 Italian\n",
      "80 Italian\n",
      "81 Italian\n",
      "82 English\n",
      "83 Italian\n",
      "84 English\n",
      "85 Italian\n",
      "86 English\n",
      "87 English\n",
      "88 English\n",
      "89 English\n",
      "90 French\n",
      "91 Italian\n",
      "92 English\n",
      "93 French\n",
      "94 English\n",
      "95 Italian\n",
      "96 Italian\n",
      "97 Italian\n",
      "98 Italian\n",
      "99 French\n",
      "100 English\n",
      "101 French\n",
      "102 Italian\n",
      "103 English\n",
      "104 English\n",
      "105 French\n",
      "106 French\n",
      "107 French\n",
      "108 French\n",
      "109 French\n",
      "110 French\n",
      "111 French\n",
      "112 French\n",
      "113 English\n",
      "114 English\n",
      "115 French\n",
      "116 English\n",
      "117 Italian\n",
      "118 Italian\n",
      "119 Italian\n",
      "120 Italian\n",
      "121 Italian\n",
      "122 Italian\n",
      "123 English\n",
      "124 English\n",
      "125 English\n",
      "126 French\n",
      "127 Italian\n",
      "128 English\n",
      "129 French\n",
      "130 Italian\n",
      "131 French\n",
      "132 French\n",
      "133 French\n",
      "134 English\n",
      "135 Italian\n",
      "136 French\n",
      "137 English\n",
      "138 French\n",
      "139 French\n",
      "140 English\n",
      "141 French\n",
      "142 English\n",
      "143 English\n",
      "144 French\n",
      "145 Italian\n",
      "146 French\n",
      "147 French\n",
      "148 Italian\n",
      "149 Italian\n",
      "150 French\n",
      "151 Italian\n",
      "152 English\n",
      "153 English\n",
      "154 French\n",
      "155 Italian\n",
      "156 English\n",
      "157 French\n",
      "158 French\n",
      "159 Italian\n",
      "160 French\n",
      "161 French\n",
      "162 English\n",
      "163 English\n",
      "164 French\n",
      "165 English\n",
      "166 English\n",
      "167 French\n",
      "168 Italian\n",
      "169 Italian\n",
      "170 English\n",
      "171 Italian\n",
      "172 Italian\n",
      "173 French\n",
      "174 English\n",
      "175 Italian\n",
      "176 French\n",
      "177 Italian\n",
      "178 English\n",
      "179 French\n",
      "180 English\n",
      "181 Italian\n",
      "182 French\n",
      "183 French\n",
      "184 Italian\n",
      "185 French\n",
      "186 Italian\n",
      "187 English\n",
      "188 French\n",
      "189 French\n",
      "190 Italian\n",
      "191 English\n",
      "192 English\n",
      "193 French\n",
      "194 English\n",
      "195 French\n",
      "196 English\n",
      "197 French\n",
      "198 French\n",
      "199 Italian\n",
      "200 Italian\n",
      "201 English\n",
      "202 French\n",
      "203 English\n",
      "204 Italian\n",
      "205 French\n",
      "206 English\n",
      "207 English\n",
      "208 French\n",
      "209 English\n",
      "210 French\n",
      "211 Italian\n",
      "212 French\n",
      "213 French\n",
      "214 Italian\n",
      "215 English\n",
      "216 English\n",
      "217 Italian\n",
      "218 French\n",
      "219 French\n",
      "220 English\n",
      "221 French\n",
      "222 English\n",
      "223 Italian\n",
      "224 English\n",
      "225 Italian\n",
      "226 Italian\n",
      "227 Italian\n",
      "228 French\n",
      "229 Italian\n",
      "230 English\n",
      "231 English\n",
      "232 Italian\n",
      "233 English\n",
      "234 Italian\n",
      "235 French\n",
      "236 English\n",
      "237 English\n",
      "238 Italian\n",
      "239 English\n",
      "240 French\n",
      "241 French\n",
      "242 Italian\n",
      "243 English\n",
      "244 English\n",
      "245 English\n",
      "246 Italian\n",
      "247 English\n",
      "248 English\n",
      "249 English\n",
      "250 English\n",
      "251 English\n",
      "252 French\n",
      "253 English\n",
      "254 Italian\n",
      "255 English\n",
      "256 English\n",
      "257 Italian\n",
      "258 Italian\n",
      "259 Italian\n",
      "260 English\n",
      "261 Italian\n",
      "262 English\n",
      "263 Italian\n",
      "264 French\n",
      "265 English\n",
      "266 French\n",
      "267 French\n",
      "268 Italian\n",
      "269 English\n",
      "270 French\n",
      "271 English\n",
      "272 French\n",
      "273 English\n",
      "274 English\n",
      "275 Italian\n",
      "276 French\n",
      "277 Italian\n",
      "278 English\n",
      "279 English\n",
      "280 French\n",
      "281 English\n",
      "282 English\n",
      "283 French\n",
      "284 Italian\n",
      "285 French\n",
      "286 French\n",
      "287 English\n",
      "288 French\n",
      "289 Italian\n",
      "290 Italian\n",
      "291 French\n",
      "292 French\n",
      "293 French\n",
      "294 Italian\n",
      "295 French\n",
      "296 French\n",
      "297 English\n",
      "298 Italian\n",
      "299 French\n",
      "300 English\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from nltk import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "langs = [\"eng\", \"french\", \"italian\"]\n",
    "names = [\"English\", \"French\", \"Italian\"]\n",
    "def problem2(lookup, file):\n",
    "    num = 1\n",
    "    for line in file.readlines():\n",
    "        \n",
    "        unigrams = word_tokenize(line)\n",
    "        bigrams = list(ngrams(unigrams, 2))\n",
    "        p_laplace = [1,1,1]\n",
    "        \n",
    "        for bigram in bigrams:\n",
    "            for i in range(3):     \n",
    "                lang = langs[i]\n",
    "                V = len(lookup[lang][\"uni\"])\n",
    "                n = lookup[lang][\"bi\"][bigram] if bigram in lookup[lang][\"bi\"] else 0\n",
    "                d = lookup[lang][\"uni\"][bigram[0]] if bigram[0] in lookup[lang][\"uni\"] else 0\n",
    "                p_laplace[i] = p_laplace[i] * ((n+1)/(d+V))\n",
    "        \n",
    "        print(f\"{num} {names[p_laplace.index(max(p_laplace))]}\")\n",
    "        num += 1\n",
    "\n",
    "        \n",
    "def main():    \n",
    "    lookup = {}\n",
    "    for lang in langs:\n",
    "        lookup[lang] = {}\n",
    "        for gram in [\"uni\", \"bi\"]:\n",
    "            lookup[lang][gram] = pickle.load(open(f\"{lang}_{gram}_dict.p\", \"rb\"))\n",
    "    problem2(lookup, open(\"data/LangId.test\"))\n",
    "          \n",
    "main()    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
